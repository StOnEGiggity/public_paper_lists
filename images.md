### -1, 2017
- [Learning to Act Properly: Predicting and Explaining Affordances from  Images](http://arxiv.org/abs/1712.07576v1), Ching-Yao Chuang, Jiaman Li, Antonio Torralba, Sanja Fidler

We address the problem of affordance reasoning in diverse scenes that appear
in the real world. Affordances relate the agent's actions to their effects when
taken on the surrounding objects. In our work, we take the egocentric view of
the scene, and aim to reason about action-object affordances that respect both
the physical world as well as the social norms imposed by the society. We also
aim to teach artificial agents why some actions should not be taken in certain
situations, and what would likely happen if these actions would be taken. We
collect a new dataset that builds upon ADE20k, referred to as ADE-Affordance,
which contains annotations enabling such rich visual reasoning. We propose a
model that exploits Graph Neural Networks to propagate contextual information
from the scene in order to perform detailed affordance reasoning about each
object. Our model is showcased through various ablation studies, pointing to
successes and challenges in this complex task.

- [Learning Intelligent Dialogs for Bounding Box Annotation](http://arxiv.org/abs/1712.08087v1), Ksenia Konyushkova, Jasper Uijlings, Christoph Lampert, Vittorio Ferrari

We introduce Intelligent Annotation Dialogs for bounding box annotation. We
train an agent to automatically choose a sequence of actions for a human
annotator to produce a bounding box in a minimal amount of time. Specifically,
we consider two actions: box verification [37], where the annotator verifies a
box generated by an object detector, and manual box drawing. We explore two
kinds of agents, one based on predicting the probability that a box will be
positively verified, and the other based on reinforcement learning. We
demonstrate that (1) our agents are able to learn efficient annotation
strategies in several scenarios, automatically adapting to the difficulty of an
input image, the desired quality of the boxes, the strength of the detector,
and other factors; (2) in all scenarios the resulting annotation dialogs speed
up annotation compared to manual box drawing alone and box verification alone,
while also out- performing any fixed combination of verification and draw- ing
in most scenarios; (3) in a realistic scenario where the detector is
iteratively re-trained, our agents evolve a series of strategies that reflect
the shifting trade-off between verification and drawing as the detector grows
stronger.
