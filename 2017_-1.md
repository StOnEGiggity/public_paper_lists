- [Riemann-Theta Boltzmann Machine](http://arxiv.org/abs/1712.07581v1), Daniel Krefl, Stefano Carrazza, Babak Haghighat, Jens Kahlen

A general Boltzmann machine with continuous visible and discrete integer
valued hidden states is introduced. Under mild assumptions about the connection
matrices, the probability density function of the visible units can be solved
for analytically, yielding a novel parametric density function involving a
ratio of Riemann-Theta functions. The conditional expectation of a hidden state
for given visible states can also be calculated analytically, yielding a
derivative of the logarithmic Riemann-Theta function. The conditional
expectation can be used as activation function in a feedforward neural network,
thereby increasing the modelling capacity of the network. Both the Boltzmann
machine and the derived feedforward neural network can be successfully trained
via standard gradient- and non-gradient-based optimization techniques.

- [On Wasserstein Reinforcement Learning and the Fokker-Planck equation](http://arxiv.org/abs/1712.07185v1), Pierre H. Richemond, Brendan Maginnis

Policy gradients methods often achieve better performance when the change in
policy is limited to a small Kullback-Leibler divergence. We derive policy
gradients where the change in policy is limited to a small Wasserstein distance
(or trust region). This is done in the discrete and continuous multi-armed
bandit settings with entropy regularisation. We show that in the small steps
limit with respect to the Wasserstein distance $W_2$, policy dynamics are
governed by the Fokker-Planck (heat) equation, following the
Jordan-Kinderlehrer-Otto result. This means that policies undergo diffusion and
advection, concentrating near actions with high reward. This helps elucidate
the nature of convergence in the probability matching setup, and provides
justification for empirical practices such as Gaussian policy priors and
additive gradient noise.

- [Discovery of Shifting Patterns in Sequence Classification](http://arxiv.org/abs/1712.07203v1), Xiaowei Jia, Ankush Khandelwal, Anuj Karpatne, Vipin Kumar

In this paper, we investigate the multi-variate sequence classification
problem from a multi-instance learning perspective. Real-world sequential data
commonly show discriminative patterns only at specific time periods. For
instance, we can identify a cropland during its growing season, but it looks
similar to a barren land after harvest or before planting. Besides, even within
the same class, the discriminative patterns can appear in different periods of
sequential data. Due to such property, these discriminative patterns are also
referred to as shifting patterns. The shifting patterns in sequential data
severely degrade the performance of traditional classification methods without
sufficient training data.
  We propose a novel sequence classification method by automatically mining
shifting patterns from multi-variate sequence. The method employs a
multi-instance learning approach to detect shifting patterns while also
modeling temporal relationships within each multi-instance bag by an LSTM model
to further improve the classification performance. We extensively evaluate our
method on two real-world applications - cropland mapping and affective state
recognition. The experiments demonstrate the superiority of our proposed method
in sequence classification performance and in detecting discriminative shifting
patterns.

- [DropMax: Adaptive Stochastic Softmax](http://arxiv.org/abs/1712.07834v2), Hae Beom Lee, Juho Lee, Eunho Yang, Sung Ju Hwang

We propose DropMax, a stochastic version of softmax classifier which at each
iteration drops non-target classes with some probability, for each instance.
Specifically, we overlay binary masking variables over class output
probabilities, which are learned based on the input via regularized variational
inference. This stochastic regularization has an effect of building an ensemble
classifier out of exponential number of classifiers with different decision
boundaries. Moreover, the learning of dropout probabilities for non-target
classes on each instance allows the classifier to focus more on classification
against the most confusing classes. We validate our model on multiple public
datasets for classification, on which it obtains improved accuracy over regular
softmax classifier and other baselines. Further analysis of the learned dropout
masks shows that our model indeed selects confusing classes more often when it
performs classification.

- [Dropout Feature Ranking for Deep Learning Models](http://arxiv.org/abs/1712.08645v1), Chun-Hao Chang, Ladislav Rampasek, Anna Goldenberg

Deep neural networks are a promising technology achieving state-of-the-art
results in biological and healthcare domains. Unfortunately, DNNs are notorious
for their non-interpretability. Clinicians are averse to black boxes and thus
interpretability is paramount to broadly adopting this technology. We aim to
close this gap by proposing a new general feature ranking method for deep
learning. We show that our method outperforms LASSO, Elastic Net, Deep Feature
Selection and various heuristics on a simulated dataset. We also compare our
method in a multivariate clinical time-series dataset and demonstrate our
ranking rivals or outperforms other methods in Recurrent Neural Network
setting. Finally, we apply our feature ranking to the Variational Autoencoder
recently proposed to predict drug response in cell lines and show that it
identifies meaningful genes corresponding to the drug response.

- [A short variational proof of equivalence between policy gradients and  soft Q learning](http://arxiv.org/abs/1712.08650v1), Pierre H. Richemond, Brendan Maginnis

Two main families of reinforcement learning algorithms, Q-learning and policy
gradients, have recently been proven to be equivalent when using a softmax
relaxation on one part, and an entropic regularization on the other. We relate
this result to the well-known convex duality of Shannon entropy and the softmax
function. Such a result is also known as the Donsker-Varadhan formula. This
provides a short proof of the equivalence. We then interpret this duality
further, and use ideas of convex analysis to prove a new policy inequality
relative to soft Q-learning.

- [Learning to Run with Actor-Critic Ensemble](http://arxiv.org/abs/1712.08987v1), Zhewei Huang, Shuchang Zhou, BoEr Zhuang, Xinyu Zhou

We introduce an Actor-Critic Ensemble(ACE) method for improving the
performance of Deep Deterministic Policy Gradient(DDPG) algorithm. At inference
time, our method uses a critic ensemble to select the best action from
proposals of multiple actors running in parallel. By having a larger candidate
set, our method can avoid actions that have fatal consequences, while staying
deterministic. Using ACE, we have won the 2nd place in NIPS'17 Learning to Run
competition, under the name of "Megvii-hzwer".

- [Deep learning for universal linear embeddings of nonlinear dynamics](http://arxiv.org/abs/1712.09707v1), Bethany Lusch, J. Nathan Kutz, Steven L. Brunton

Identifying coordinate transformations that make strongly nonlinear dynamics
approximately linear is a central challenge in modern dynamical systems. These
transformations have the potential to enable prediction, estimation, and
control of nonlinear systems using standard linear theory. The Koopman operator
has emerged as a leading data-driven embedding, as eigenfunctions of this
operator provide intrinsic coordinates that globally linearize the dynamics.
However, identifying and representing these eigenfunctions has proven to be
mathematically and computationally challenging. This work leverages the power
of deep learning to discover representations of Koopman eigenfunctions from
trajectory data of dynamical systems. Our network is parsimonious and
interpretable by construction, embedding the dynamics on a low-dimensional
manifold that is of the intrinsic rank of the dynamics and parameterized by the
Koopman eigenfunctions. In particular, we identify nonlinear coordinates on
which the dynamics are globally linear using a modified auto-encoder. We also
generalize Koopman representations to include a ubiquitous class of systems
that exhibit continuous spectra, ranging from the simple pendulum to nonlinear
optics and broadband turbulence. Our framework parametrizes the continuous
frequency using an auxiliary network, enabling a compact and efficient
embedding at the intrinsic rank, while connecting our models to half a century
of asymptotics. In this way, we benefit from the power and generality of deep
learning, while retaining the physical interpretability of Koopman embeddings.

- [On Convergence of some Gradient-based Temporal-Differences Algorithms  for Off-Policy Learning](http://arxiv.org/abs/1712.09652v1), Huizhen Yu

We consider off-policy temporal-difference (TD) learning methods for policy
evaluation in Markov decision processes with finite spaces and discounted
reward criteria, and we present a collection of convergence results for several
gradient-based TD algorithms with linear function approximation. The algorithms
we analyze include: (i) two basic forms of two-time-scale gradient-based TD
algorithms, which we call GTD and which minimize the mean squared projected
Bellman error using stochastic gradient-descent; (ii) their "robustified"
biased variants; (iii) their mirror-descent versions which combine the
mirror-descent idea with TD learning; and (iv) a single-time-scale version of
GTD that solves minimax problems formulated for approximate policy evaluation.
  We derive convergence results for three types of stepsizes: constant
stepsize, slowly diminishing stepsize, as well as the standard type of
diminishing stepsize with a square-summable condition. For the first two types
of stepsizes, we apply the weak convergence method from stochastic
approximation theory to characterize the asymptotic behavior of the algorithms,
and for the standard type of stepsize, we analyze the algorithmic behavior with
respect to a stronger mode of convergence, almost sure convergence. Our
convergence results are for the aforementioned TD algorithms with three general
ways of setting their $\lambda$-parameters: (i) state-dependent $\lambda$; (ii)
a recently proposed scheme of using history-dependent $\lambda$ to keep the
eligibility traces of the algorithms bounded while allowing for relatively
large values of $\lambda$; and (iii) a composite scheme of setting the
$\lambda$-parameters that combines the preceding two schemes and allows a
broader class of generalized Bellman operators to be used for approximate
policy evaluation with TD methods.

- [Learning Rapid-Temporal Adaptations](http://arxiv.org/abs/1712.09926v1), Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, Tong Wang, Adam Trischler

A hallmark of human intelligence and cognition is its flexibility. One of the
long-standing goals in AI research is to replicate this flexibility in a
learning machine. In this work we describe a mechanism by which artificial
neural networks can learn rapid-temporal adaptation - the ability to adapt
quickly to new environments or tasks - that we call adaptive neurons. Adaptive
neurons modify their activations with task-specific values retrieved from a
working memory. On standard metalearning and few-shot learning benchmarks in
both vision and language domains, models augmented with adaptive neurons
achieve state-of-the-art results.

- [Variational Attention for Sequence-to-Sequence Models](http://arxiv.org/abs/1712.08207v1), Hareesh Bahuleyan, Lili Mou, Olga Vechtomova, Pascal Poupart

The variational encoder-decoder (VED) encodes source information as a set of
random variables using a neural network, which in turn is decoded into target
data using another neural network. In natural language processing,
sequence-to-sequence (Seq2Seq) models typically serve as encoder-decoder
networks. When combined with a traditional (deterministic) attention mechanism,
the variational latent space may be bypassed by the attention model, making the
generated sentences less diversified. In our paper, we propose a variational
attention mechanism for VED, where the attention vector is modeled as normally
distributed random variables. Experiments show that variational attention
increases diversity while retaining high quality. We also show that the model
is not sensitive to hyperparameters.

- [Letter-Based Speech Recognition with Gated ConvNets](http://arxiv.org/abs/1712.09444v1), Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan Collobert

In this paper we introduce a new speech recognition system, leveraging a
simple letter-based ConvNet acoustic model. The acoustic model requires -- only
audio transcription for training -- no alignment annotations, nor any forced
alignment step is needed. At inference, our decoder takes only a word list and
a language model, and is fed with letter scores from the -- acoustic model --
no phonetic word lexicon is needed. Key ingredients for the acoustic model are
Gated Linear Units and high dropout. We show near state-of-the-art results in
word error rate on the LibriSpeech corpus using log-mel filterbanks, both on
the "clean" and "other" configurations.

- [Wav2Letter: an End-to-End ConvNet-based Speech Recognition System](http://arxiv.org/abs/1609.03193v2), Ronan Collobert, Christian Puhrsch, Gabriel Synnaeve

This paper presents a simple end-to-end model for speech recognition,
combining a convolutional network based acoustic model and a graph decoding. It
is trained to output letters, with transcribed speech, without the need for
force alignment of phonemes. We introduce an automatic segmentation criterion
for training from sequence annotation without alignment that is on par with CTC
while being simpler. We show competitive results in word error rate on the
Librispeech corpus with MFCC features, and promising results from raw waveform.

- [Toward Continual Learning for Conversational Agents](http://arxiv.org/abs/1712.09943v1), Sungjin Lee

While end-to-end neural conversation models have led to promising advances in
reducing hand-crafted features and errors induced by the traditional complex
system architecture, they typically require an enormous amount of data.
Previous studies adopted a hybrid approach with knowledge-based components to
abstract out domain-specific things or to augment data to cover more diverse
patterns. On the contrary, we propose to directly address the problem using the
recent development in the space of continual learning for neural models.
Specifically, we adopt a domain-independent neural conversational model and
introduce a novel neural continual learning algorithm that allows the
conversational agent to accumulate skills across different tasks in a
data-efficient way. To the best of our knowledge, this is the first work that
applies continual learning for conversation systems. We verified the efficacy
of our method through a conversational skill transfer from synthetic dialogs or
human-human dialogs to human-computer conversations in a customer support
domain.



- [Smart, Sparse Contours to Represent and Edit Images](http://arxiv.org/abs/1712.08232v1), Tali Dekel, Chuang Gan, Dilip Krishnan, Ce Liu, William T. Freeman

We study the problem of reconstructing an image from information stored at
sparse contour locations. Existing contour-based image reconstruction methods
struggle to balance contour sparsity and reconstruction fidelity. Therefore,
denser contours are needed to capture subtle texture information even though
contours were not meant for textures. We propose a novel image representation
where image content is characterized by contours with gradient information via
an encoder-decoder network, while image details are modeled by a conditional
generative adversarial network. We show that high-quality reconstructions with
high fidelity to the source image can be obtained from extremely sparse input,
e.g., comprising less than 6% of image pixels. Our model synthesizes texture,
details and fine structures in regions where no input information is provided.
The semantic knowledge encoded into our model and the sparsity of the input
allows using contours as an intuitive interface for semantically-aware image
manipulation: local edits in contour domain such as scaling, translation and
erasing, translate to long-range and coherent changes in the pixel space.
Experiments on a variety of datasets verify the versatility and convenience
afforded by our models.

- [Consensus-based Sequence Training for Video Captioning](http://arxiv.org/abs/1712.09532v1), Sang Phan, Gustav Eje Henter, Yusuke Miyao, Shin'ichi Satoh

Captioning models are typically trained using the cross-entropy loss.
However, their performance is evaluated on other metrics designed to better
correlate with human assessments. Recently, it has been shown that
reinforcement learning (RL) can directly optimize these metrics in tasks such
as captioning. However, this is computationally costly and requires specifying
a baseline reward at each step to make training converge. We propose a fast
approach to optimize one's objective of interest through the REINFORCE
algorithm. First we show that, by replacing model samples with ground-truth
sentences, RL training can be seen as a form of weighted cross-entropy loss,
giving a fast, RL-based pre-training algorithm. Second, we propose to use the
consensus among ground-truth captions of the same video as the baseline reward.
This can be computed very efficiently. We call the complete proposal
Consensus-based Sequence Training (CST). Applied to the MSRVTT video captioning
benchmark, our proposals train significantly faster than comparable methods and
establish a new state-of-the-art on the task, improving the CIDEr score from
47.3 to 54.2.

- [Exploring the Space of Black-box Attacks on Deep Neural Networks](http://arxiv.org/abs/1712.09491v1), Arjun Nitin Bhagoji, Warren He, Bo Li, Dawn Song

Existing black-box attacks on deep neural networks (DNNs) so far have largely
focused on transferability, where an adversarial instance generated for a
locally trained model can "transfer" to attack other learning models. In this
paper, we propose novel Gradient Estimation black-box attacks for adversaries
with query access to the target model's class probabilities, which do not rely
on transferability. We also propose strategies to decouple the number of
queries required to generate each adversarial sample from the dimensionality of
the input. An iterative variant of our attack achieves close to 100%
adversarial success rates for both targeted and untargeted attacks on DNNs. We
carry out extensive experiments for a thorough comparative evaluation of
black-box attacks and show that the proposed Gradient Estimation attacks
outperform all transferability based black-box attacks we tested on both MNIST
and CIFAR-10 datasets, achieving adversarial success rates similar to well
known, state-of-the-art white-box attacks. We also apply the Gradient
Estimation attacks successfully against a real-world Content Moderation
classifier hosted by Clarifai. Furthermore, we evaluate black-box attacks
against state-of-the-art defenses. We show that the Gradient Estimation attacks
are very effective even against these defenses.


- [Deep Meta Learning for Real-Time Visual Tracking based on  Target-Specific Feature Space](http://arxiv.org/abs/1712.09153v1), Janghoon Choi, Junseok Kwon, Kyoung Mu Lee

In this paper, we propose a novel on-line visual tracking framework based on
Siamese matching network and meta-learner network which runs at real-time
speed. Conventional deep convolutional feature based discriminative visual
tracking algorithms require continuous re-training of classifiers or
correlation filters for solving complex optimization tasks to adapt to the new
appearance of a target object. To remove this process, our proposed algorithm
incorporates and utilizes a meta-learner network to provide the matching
network with new appearance information of the target object by adding the
target-aware feature space. The parameters for the target-specific feature
space are provided instantly from a single forward-pass of the meta-learner
network. By eliminating the necessity of continuously solving the complex
optimization tasks in the course of tracking, experimental results demonstrate
that our algorithm performs at a real-time speed of $62$ fps while maintaining
a competitive performance among other state-of-the-art tracking algorithms.

- [Future Frame Prediction for Anomaly Detection -- A New Baseline](http://arxiv.org/abs/1712.09867v1), Wen Liu, Weixin Luo, Dongze Lian, Shenghua Gao

Anomaly detection in videos refers to the identification of events that do
not conform to expected behavior. However, almost all existing methods tackle
the problem by minimizing the reconstruction errors of training data, which
cannot guarantee a larger reconstruction error for an abnormal event. In this
paper, we propose to tackle the anomaly detection problem within a video
prediction framework. To the best of our knowledge, this is the first work that
leverages the difference between a predicted future frame and its ground truth
to detect an abnormal event. To predict a future frame with higher quality for
normal events, other than the commonly used appearance (spatial) constraints on
intensity and gradient, we also introduce a motion (temporal) constraint in
video prediction by enforcing the optical flow between predicted frames and
ground truth frames to be consistent, and this is the first work that
introduces a temporal constraint into the video prediction task. Such spatial
and motion constraints facilitate the future frame prediction for normal
events, and consequently facilitate to identify those abnormal events that do
not conform the expectation. Extensive experiments on both a toy dataset and
some publicly available datasets validate the effectiveness of our method in
terms of robustness to the uncertainty in normal events and the sensitivity to
abnormal events

- [Taking Visual Motion Prediction To New Heightfields](http://arxiv.org/abs/1712.09448v1), Sebastien Ehrhardt, Aron Monszpart, Niloy Mitra, Andrea Vedaldi

While the basic laws of Newtonian mechanics are well understood, explaining a
physical scenario still requires manually modeling the problem with suitable
equations and estimating the associated parameters. In order to be able to
leverage the approximation capabilities of artificial intelligence techniques
in such physics related contexts, researchers have handcrafted the relevant
states, and then used neural networks to learn the state transitions using
simulation runs as training data. Unfortunately, such approaches are unsuited
for modeling complex real-world scenarios, where manually authoring relevant
state spaces tend to be tedious and challenging. In this work, we investigate
if neural networks can implicitly learn physical states of real-world
mechanical processes only based on visual data while internally modeling
non-homogeneous environment and in the process enable long-term physical
extrapolation. We develop a recurrent neural network architecture for this task
and also characterize resultant uncertainties in the form of evolving variance
estimates. We evaluate our setup to extrapolate motion of rolling ball(s) on
bowls of varying shape and orientation, and on arbitrary heightfields using
only images as input. We report significant improvements over existing
image-based methods both in terms of accuracy of predictions and complexity of
scenarios; and report competitive performance with approaches that, unlike us,
assume access to internal physical states.
